{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from desdeo_problem.Objective import _ScalarObjective\n",
    "from desdeo_problem.Variable import variable_builder\n",
    "from desdeo_problem.Problem import MOProblem\n",
    "from desdeo_emo.EAs.RVEA import RVEA\n",
    "from desdeo_emo.othertools.plotlyanimate import animate_init_, animate_next_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Objectives and variable builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_1(x):\n",
    "    term = x[:, 0]**2 + x[:, 1]**2\n",
    "    return 0.5*term + np.sin(term)\n",
    "\n",
    "def f_2(x):\n",
    "    term1 = ((3*x[:, 0] - 2*x[:,1] + 4)**2)/8\n",
    "    term2 = ((x[:, 0] - x[:,1] + 1)**2)/27\n",
    "    return term1 + term2 + 15\n",
    "\n",
    "def f_3(x):\n",
    "    term = x[:, 0]**2 + x[:, 1]**2\n",
    "    return (1/(term + 1)) - 1.1 * np.exp(-term)\n",
    "\n",
    "list_vars = variable_builder(['x', 'y'],\n",
    "                             initial_values = [0,0],\n",
    "                             lower_bounds=[-30, -30],\n",
    "                             upper_bounds=[30, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = _ScalarObjective(name='f1', evaluator=f_1)\n",
    "f2 = _ScalarObjective(name='f2', evaluator=f_2)\n",
    "f3 = _ScalarObjective(name='f3', evaluator=f_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from desdeo_problem.Constraint import ScalarConstraint\n",
    "\n",
    "const_func_1 = lambda x, y: (y[:, 0] - .2) * (y[:, 0] - .4)\n",
    "const_func_2 = lambda x, y: y[:, 1] - 50\n",
    "\n",
    "# Args: name, number of variables, number of objectives, callable\n",
    "cons1 = ScalarConstraint(\"c_1\", 2, 2, const_func_1)\n",
    "cons2 = ScalarConstraint(\"c_2\", 2, 2, const_func_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MOProblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = MOProblem(variables=list_vars, objectives=[f1, f2], constraints=[cons1])\n",
    "\n",
    "# problem = MOProblem(variables=list_vars, objectives=[f1, f2])\n",
    "\n",
    "evolver = RVEA(problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as:  MOP5.html\n",
      "View the plot by opening the file in browser.\n",
      "To view the plot in Jupyter Notebook, use the IFrame command.\n"
     ]
    }
   ],
   "source": [
    "figure = animate_init_(evolver.population.objectives, filename=\"MOP5.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "0.1\n",
      "---------------------------\n",
      "0.2\n",
      "---------------------------\n",
      "0.3\n",
      "---------------------------\n",
      "0.4\n",
      "---------------------------\n",
      "0.5\n",
      "---------------------------\n",
      "0.6\n",
      "---------------------------\n",
      "0.7\n",
      "---------------------------\n",
      "0.8\n",
      "---------------------------\n",
      "0.9\n",
      "---------------------------\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i<10:\n",
    "    print('---------------------------')\n",
    "    i += 1\n",
    "    evolver.iterate()\n",
    "    print(evolver.selection_operator.time_penalty_function())\n",
    "    figure = animate_next_(\n",
    "        evolver.population.objectives,\n",
    "        figure,\n",
    "        filename=\"MOP5.html\",\n",
    "        generation=evolver._iteration_counter,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results Object \n",
      "Objective values are: \n",
      "[[ 1.54107573 16.125     ]]\n",
      "Constraint violation values are: \n",
      "[[-18.45892427 -33.875     ]]\n",
      "Fitness values are: \n",
      "[[ 1.54107573 16.125     ]]\n",
      "Uncertainity values are: \n",
      "[[nan nan]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(problem.evaluate(np.asarray([[1,2]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.88504426e-01,  3.39102647e-01],\n",
       "       [-4.32204571e-01,  2.82451180e-01],\n",
       "       [-6.27914764e-01,  3.81794523e-01],\n",
       "       [-3.31773159e-01,  2.27840039e-01],\n",
       "       [-4.54691525e-01,  3.47203691e-01],\n",
       "       [-5.34275313e-01,  3.14458834e-01],\n",
       "       [-7.89522725e-02,  2.57619481e-02],\n",
       "       [-6.31339188e-04,  3.68708336e-02],\n",
       "       [-6.23479207e+00, -7.27988709e+00],\n",
       "       [-5.54160281e-04,  1.65296720e-02],\n",
       "       [-2.65726154e-01,  1.74885922e-01],\n",
       "       [-1.54647223e-01,  1.05033533e-01],\n",
       "       [-3.09060828e-01,  2.27326566e-01],\n",
       "       [-7.57358717e-01,  4.73835992e-01],\n",
       "       [-1.77194820e-01,  1.72657917e-01],\n",
       "       [-4.81905179e-01,  3.65926913e-01],\n",
       "       [-4.35015397e-02,  3.68645120e-02],\n",
       "       [-4.43893794e-01,  2.81441967e-01],\n",
       "       [-4.73466229e-01,  3.52006908e-01],\n",
       "       [-5.49821778e-01,  4.28527576e-01],\n",
       "       [-4.53047243e-01,  3.12006872e-01],\n",
       "       [-2.48831390e-01,  1.17919241e-01],\n",
       "       [-6.53849157e-02,  1.71082115e-02],\n",
       "       [ 1.72162856e+01, -2.16029693e+01],\n",
       "       [ 9.89446602e+00, -8.75369721e-01],\n",
       "       [-5.47141999e-01,  3.14809566e-01],\n",
       "       [ 1.69459587e+01, -3.65118033e+00],\n",
       "       [-1.72675618e-01,  4.80915705e-02],\n",
       "       [-1.57720579e-02,  2.17902420e-02],\n",
       "       [-1.69438215e-02,  2.58939921e-02],\n",
       "       [-5.83930506e-01,  4.27302930e-01],\n",
       "       [-3.83783565e-01,  2.70369430e-01],\n",
       "       [-1.35434630e+01, -1.79115920e+01],\n",
       "       [-4.00808779e-01,  2.58898435e-01],\n",
       "       [-1.92575089e+01, -2.23410348e+00],\n",
       "       [-2.92959979e-01,  2.11800294e-01],\n",
       "       [-1.46701553e-01,  1.33409117e-01],\n",
       "       [-5.45774792e-01,  3.39661527e-01],\n",
       "       [-1.91691529e-02,  4.50437711e-02],\n",
       "       [-2.46870792e-01,  1.74470797e-01],\n",
       "       [-3.47682968e-01,  2.47349461e-01],\n",
       "       [-5.54903323e-01,  3.57804184e-01],\n",
       "       [-3.80933860e-01,  2.67688426e-01],\n",
       "       [ 3.22885112e+00, -2.57746575e+01],\n",
       "       [-1.30123341e+01, -1.74119599e+01],\n",
       "       [-4.37951455e-01,  2.63671595e-01],\n",
       "       [-3.69090035e-01,  2.53061433e-01],\n",
       "       [-1.83833764e-01,  1.16692306e-01],\n",
       "       [-9.18341812e-01, -2.90569082e+01],\n",
       "       [-1.52476826e-01,  7.44337059e-02],\n",
       "       [ 1.63730967e+01, -2.09764606e+01],\n",
       "       [-1.17165250e-02,  1.74654811e-03],\n",
       "       [-2.41271226e-01,  1.56934472e-01],\n",
       "       [-6.53561854e-02,  9.30704181e-02],\n",
       "       [-2.45536694e-01,  1.62976954e-01],\n",
       "       [-1.52804549e-01,  1.68120731e-01],\n",
       "       [-1.45383867e-01,  7.40073427e-02],\n",
       "       [-3.74747258e-01,  2.58854645e-01],\n",
       "       [-1.47199908e-01,  5.74339728e-02],\n",
       "       [-4.58324161e-01,  3.29006605e-01],\n",
       "       [-2.79456121e-01,  2.02541349e-01],\n",
       "       [-3.02016763e-01,  2.30820557e-01],\n",
       "       [ 9.79688757e-04,  1.27232873e-03],\n",
       "       [-5.79020744e-01,  4.15498493e-01],\n",
       "       [-1.56079054e-02,  3.93302809e-02],\n",
       "       [-1.57456627e+01, -2.11183509e+01],\n",
       "       [-3.54565193e-01,  2.30248993e-01],\n",
       "       [-2.17342077e+01, -3.00000000e+01],\n",
       "       [-5.30422651e+00, -2.99130037e+01],\n",
       "       [-4.53571163e-01,  2.82773201e-01],\n",
       "       [-3.52871160e-01,  2.49084219e-01],\n",
       "       [-2.66937420e-01,  2.02027625e-01],\n",
       "       [-6.56114592e-03,  2.07586785e-02],\n",
       "       [-2.23274733e-01,  1.32916034e-01],\n",
       "       [-2.04090671e-01,  1.19503259e-01],\n",
       "       [-2.27283434e-01,  1.35232388e-01],\n",
       "       [-2.87480975e-01,  2.03654925e-01],\n",
       "       [ 5.76419712e+00, -2.10683814e+01],\n",
       "       [-4.30705851e-01,  2.43686410e-01],\n",
       "       [-2.93327971e-01,  2.21858474e-01],\n",
       "       [-1.82222809e+01, -2.48183747e+01],\n",
       "       [-2.99044957e-01,  2.26147359e-01],\n",
       "       [-2.92491419e-01,  1.75422137e-01],\n",
       "       [-1.73531229e-01,  1.18676862e-01],\n",
       "       [-3.42373180e+00, -2.76732495e+01],\n",
       "       [-8.31582529e+00, -1.04543193e+01],\n",
       "       [-2.58667492e-01,  1.63094627e-01],\n",
       "       [-3.61539077e-01,  2.50742245e-01],\n",
       "       [-1.01033922e+01, -1.28559403e+01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evolver.population.individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (9, 9, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RVEA in module desdeo_emo.EAs.RVEA:\n",
      "\n",
      "class RVEA(desdeo_emo.EAs.BaseEA.BaseDecompositionEA)\n",
      " |  RVEA(problem: desdeo_problem.Problem.MOProblem, population_size: int = None, population_params: Dict = None, initial_population: desdeo_emo.population.Population.Population = None, alpha: float = None, lattice_resolution: int = None, a_priori: bool = False, interact: bool = False, n_iterations: int = 10, n_gen_per_iter: int = 100, total_function_evaluations: int = 0, time_penalty_component: Union[str, float] = None)\n",
      " |  \n",
      " |  The python version reference vector guided evolutionary algorithm.\n",
      " |  \n",
      " |  Most of the relevant code is contained in the super class. This class just assigns\n",
      " |  the APD selection operator to BaseDecompositionEA.\n",
      " |  \n",
      " |  NOTE: The APD function had to be slightly modified to accomodate for the fact that\n",
      " |  this version of the algorithm is interactive, and does not have a set termination\n",
      " |  criteria. There is a time component in the APD penalty function formula of the type:\n",
      " |  (t/t_max)^alpha. As there is no set t_max, the formula has been changed. See below,\n",
      " |  the documentation for the argument: penalty_time_component\n",
      " |  \n",
      " |  See the details of RVEA in the following paper\n",
      " |  \n",
      " |  R. Cheng, Y. Jin, M. Olhofer and B. Sendhoff, A Reference Vector Guided\n",
      " |  Evolutionary Algorithm for Many-objective Optimization, IEEE Transactions on\n",
      " |  Evolutionary Computation, 2016\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  problem : MOProblem\n",
      " |      The problem class object specifying the details of the problem.\n",
      " |  population_size : int, optional\n",
      " |      The desired population size, by default None, which sets up a default value\n",
      " |      of population size depending upon the dimensionaly of the problem.\n",
      " |  population_params : Dict, optional\n",
      " |      The parameters for the population class, by default None. See\n",
      " |      desdeo_emo.population.Population for more details.\n",
      " |  initial_population : Population, optional\n",
      " |      An initial population class, by default None. Use this if you want to set up\n",
      " |      a specific starting population, such as when the output of one EA is to be\n",
      " |      used as the input of another.\n",
      " |  alpha : float, optional\n",
      " |      The alpha parameter in the APD selection mechanism. Read paper for details.\n",
      " |  lattice_resolution : int, optional\n",
      " |      The number of divisions along individual axes in the objective space to be\n",
      " |      used while creating the reference vector lattice by the simplex lattice\n",
      " |      design. By default None\n",
      " |  a_priori : bool, optional\n",
      " |      A bool variable defining whether a priori preference is to be used or not.\n",
      " |      By default False\n",
      " |  interact : bool, optional\n",
      " |      A bool variable defining whether interactive preference is to be used or\n",
      " |      not. By default False\n",
      " |  n_iterations : int, optional\n",
      " |      The total number of iterations to be run, by default 10. This is not a hard\n",
      " |      limit and is only used for an internal counter.\n",
      " |  n_gen_per_iter : int, optional\n",
      " |      The total number of generations in an iteration to be run, by default 100.\n",
      " |      This is not a hard limit and is only used for an internal counter.\n",
      " |  total_function_evaluations :int, optional\n",
      " |      Set an upper limit to the total number of function evaluations. When set to\n",
      " |      zero, this argument is ignored and other termination criteria are used.\n",
      " |  penalty_time_component: Union[str, float], optional\n",
      " |      The APD formula had to be slightly changed.\n",
      " |      If penalty_time_component is a float between [0, 1], (t/t_max) is replaced by\n",
      " |      that constant for the entire algorithm.\n",
      " |      If penalty_time_component is \"original\", the original intent of the paper is\n",
      " |      followed and (t/t_max) is calculated as\n",
      " |      (current generation count/total number of generations).\n",
      " |      If penalty_time_component is \"function_count\", (t/t_max) is calculated as\n",
      " |      (current function evaluation count/total number of function evaluations)\n",
      " |      If penalty_time_component is \"interactive\", (t/t_max)  is calculated as\n",
      " |      (Current gen count within an iteration/Total gen count within an iteration).\n",
      " |      Hence, time penalty is always zero at the beginning of each iteration, and one\n",
      " |      at the end of each iteration.\n",
      " |      Note: If the penalty_time_component ever exceeds one, the value one is used as\n",
      " |      the penalty_time_component.\n",
      " |      If no value is provided, an appropriate default is selected.\n",
      " |      If `interact` is true, penalty_time_component is \"interactive\" by default.\n",
      " |      If `interact` is false, but `total_function_evaluations` is provided,\n",
      " |      penalty_time_component is \"function_count\" by default.\n",
      " |      If `interact` is false, but `total_function_evaluations` is not provided,\n",
      " |      penalty_time_component is \"original\" by default.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RVEA\n",
      " |      desdeo_emo.EAs.BaseEA.BaseDecompositionEA\n",
      " |      desdeo_emo.EAs.BaseEA.BaseEA\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, problem: desdeo_problem.Problem.MOProblem, population_size: int = None, population_params: Dict = None, initial_population: desdeo_emo.population.Population.Population = None, alpha: float = None, lattice_resolution: int = None, a_priori: bool = False, interact: bool = False, n_iterations: int = 10, n_gen_per_iter: int = 100, total_function_evaluations: int = 0, time_penalty_component: Union[str, float] = None)\n",
      " |      Initialize EA here. Set up parameters, create EA specific objects.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from desdeo_emo.EAs.BaseEA.BaseDecompositionEA:\n",
      " |  \n",
      " |  manage_preferences(self, preference=None)\n",
      " |      Run the interruption phase of EA.\n",
      " |      \n",
      " |      Use this phase to make changes to RVEA.params or other objects.\n",
      " |      Updates Reference Vectors (adaptation), conducts interaction with the user.\n",
      " |  \n",
      " |  request_plot(self) -> desdeo_tools.interaction.request.SimplePlotRequest\n",
      " |  \n",
      " |  request_preferences(self) -> Union[NoneType, desdeo_tools.interaction.request.ReferencePointPreference]\n",
      " |  \n",
      " |  requests(self) -> Tuple\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from desdeo_emo.EAs.BaseEA.BaseEA:\n",
      " |  \n",
      " |  check_FE_count(self) -> bool\n",
      " |      Checks whether termination criteria via function evaluation count has been\n",
      " |          met or not.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bool: True is function evaluation count limit NOT met.\n",
      " |  \n",
      " |  continue_evolution(self) -> bool\n",
      " |      Checks whether the current iteration should be continued or not.\n",
      " |  \n",
      " |  continue_iteration(self)\n",
      " |      Checks whether the current iteration should be continued or not.\n",
      " |  \n",
      " |  iterate(self, preference=None) -> Tuple\n",
      " |      Run one iteration of EA.\n",
      " |      \n",
      " |      One iteration consists of a constant or variable number of\n",
      " |      generations. This method leaves EA.params unchanged, except the current\n",
      " |      iteration count and gen count.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from desdeo_emo.EAs.BaseEA.BaseEA:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RVEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btp_env_new",
   "language": "python",
   "name": "btp_env_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
